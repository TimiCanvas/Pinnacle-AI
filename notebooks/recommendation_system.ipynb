{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9c2dd9",
   "metadata": {},
   "source": [
    "# Hybrid Banking Recommendation System: ALS + LLM\n",
    "## Zenith Bank Product Recommendation Engine\n",
    "\n",
    "This notebook implements a hybrid recommendation system that combines:\n",
    "1. **Collaborative Filtering (ALS)** - For data-driven product recommendations\n",
    "2. **LLM (GPT-4)** - For context awareness, explanations, and personalization\n",
    "\n",
    "**Architecture:**\n",
    "- ALS generates base recommendations from transaction patterns\n",
    "- LLM enhances with context, explanations, and customer segmentation\n",
    "- Feature engineering creates rich customer profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1101297",
   "metadata": {},
   "source": [
    "## Cell 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4621e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "#!pip install -q openai python-dotenv implicit scikit-learn scipy pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441c427",
   "metadata": {},
   "source": [
    "## Cell 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58656198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, ndcg_score\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import backoff\n",
    "\n",
    "\n",
    "import time\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window\n",
    "import json\n",
    "from decimal import Decimal\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e4fbe4",
   "metadata": {},
   "source": [
    "## Cell 3: Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6933a732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Configuration Loaded from .env:\n",
      "{\n",
      "  \"als\": {\n",
      "    \"factors\": 50,\n",
      "    \"regularization\": 0.01,\n",
      "    \"iterations\": 15,\n",
      "    \"alpha\": 40.0\n",
      "  },\n",
      "  \"llm\": {\n",
      "    \"model\": \"gpt-4o-mini\",\n",
      "    \"temperature\": 0.3,\n",
      "    \"max_tokens\": 2000\n",
      "  },\n",
      "  \"recommendation\": {\n",
      "    \"top_n\": 5,\n",
      "    \"final_n\": 3\n",
      "  },\n",
      "  \"feature_engineering\": {\n",
      "    \"recency_days\": 90,\n",
      "    \"min_transactions\": 3\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# API KEYS AND CONFIGURATION (loaded from .env)\n",
    "# ============================================================================\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "CONFIG = {\n",
    "    'als': {\n",
    "        'factors': int(os.getenv('ALS_FACTORS', 50)),\n",
    "        'regularization': float(os.getenv('ALS_REGULARIZATION', 0.01)),\n",
    "        'iterations': int(os.getenv('ALS_ITERATIONS', 15)),\n",
    "        'alpha': float(os.getenv('ALS_ALPHA', 40.0))\n",
    "    },\n",
    "    'llm': {\n",
    "        'model': os.getenv('LLM_MODEL', 'gpt-4o-mini'),\n",
    "        'temperature': float(os.getenv('LLM_TEMPERATURE', 0.3)),\n",
    "        'max_tokens': int(os.getenv('LLM_MAX_TOKENS', 2000))\n",
    "    },\n",
    "    'recommendation': {\n",
    "        'top_n': int(os.getenv('RECOMMENDATION_TOP_N', 5)),\n",
    "        'final_n': int(os.getenv('RECOMMENDATION_FINAL_N', 3))\n",
    "    },\n",
    "    'feature_engineering': {\n",
    "        'recency_days': int(os.getenv('FEATURE_RECENCY_DAYS', 90)),\n",
    "        'min_transactions': int(os.getenv('FEATURE_MIN_TRANSACTIONS', 3))\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“Š Configuration Loaded from .env:\")\n",
    "print(json.dumps(CONFIG, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585a32a",
   "metadata": {},
   "source": [
    "## Cell 4: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca850beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark session initialized successfully\n",
      "ðŸ“‚ Loading datasets...\n",
      "\n",
      "âœ… Loaded 1,200,000 transactions\n",
      "âœ… Loaded 42 products\n",
      "âœ… Loaded 1,200,000 transactions\n",
      "âœ… Loaded 42 products\n",
      "âœ… Loaded 3,164 conversations\n",
      "âœ… Loaded 3,164 conversations\n",
      "âœ… Loaded 100,000 customers\n",
      "\n",
      "ðŸ“Š Schema Preview:\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- Trans_Amount: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Destination: string (nullable = true)\n",
      " |-- Deb_or_credit: string (nullable = true)\n",
      " |-- Narration: string (nullable = true)\n",
      " |-- Tran_Id: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Account_Type: string (nullable = true)\n",
      "\n",
      "âœ… Loaded 100,000 customers\n",
      "\n",
      "ðŸ“Š Schema Preview:\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- Trans_Amount: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Destination: string (nullable = true)\n",
      " |-- Deb_or_credit: string (nullable = true)\n",
      " |-- Narration: string (nullable = true)\n",
      " |-- Tran_Id: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Account_Type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PinnacleAI_DataLoad\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"âœ… Spark session initialized successfully\")\n",
    "\n",
    "# File paths\n",
    "TRANSACTIONS_TABLE = r'C:\\Users\\adeye\\Documents\\Pinnacle-AI\\dataset\\transaction.csv'\n",
    "PRODUCTS_TABLE = r'C:\\Users\\adeye\\Documents\\Pinnacle-AI\\dataset\\product.csv'\n",
    "CONVERSATIONS_TABLE = r'C:\\Users\\adeye\\Documents\\Pinnacle-AI\\dataset\\interaction_pd.csv'\n",
    "CUSTOMERS_TABLE = r'C:\\Users\\adeye\\Documents\\Pinnacle-AI\\dataset\\customers.csv'\n",
    "\n",
    "print(\"ðŸ“‚ Loading datasets...\\n\")\n",
    "\n",
    "try:\n",
    "    df_transactions = spark.read.option(\"header\", True).csv(TRANSACTIONS_TABLE)\n",
    "    df_products = spark.read.option(\"header\", True).csv(PRODUCTS_TABLE)\n",
    "    df_conversations = spark.read.option(\"header\", True).csv(CONVERSATIONS_TABLE)\n",
    "    df_customers = spark.read.option(\"header\", True).csv(CUSTOMERS_TABLE)\n",
    "\n",
    "    print(f\"âœ… Loaded {df_transactions.count():,} transactions\")\n",
    "    print(f\"âœ… Loaded {df_products.count():,} products\")\n",
    "    print(f\"âœ… Loaded {df_conversations.count():,} conversations\")\n",
    "    print(f\"âœ… Loaded {df_customers.count():,} customers\")\n",
    "\n",
    "    print(\"\\nðŸ“Š Schema Preview:\")\n",
    "    df_transactions.printSchema()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dad4387",
   "metadata": {},
   "source": [
    "## Cell 5: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2381f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TRANSACTIONS SAMPLE:\n",
      "+-----------+------------+----------+---------------------+-------------+--------------------+-----------+---------+----------------------------+\n",
      "|Customer_ID|Trans_Amount|Date      |Destination          |Deb_or_credit|Narration           |Tran_Id    |Category |Account_Type                |\n",
      "+-----------+------------+----------+---------------------+-------------+--------------------+-----------+---------+----------------------------+\n",
      "|ZB060544   |2161947.29  |2023-01-01|Maintenance Services |D            |service charge      |TR000054680|Housing  |Timeless Account Savings    |\n",
      "|ZB032114   |11331.88    |2023-01-01|Mobil Filling Station|D            |premium motor spirit|TR000874920|Transport|Gold Premium Current Account|\n",
      "|ZB096997   |497269.45   |2023-01-01|JAMB Registration    |D            |school fees payment |TR000315856|Education|Timeless Account Current    |\n",
      "|ZB011060   |382993.75   |2023-01-01|Slot Limited         |D            |fashion items       |TR000827345|Shopping |Timeless Account Savings    |\n",
      "|ZB020249   |1706431.91  |2023-01-01|Mobile Transfer      |C            |bill settlement     |TR000010619|Transfer |Gold Premium Current Account|\n",
      "+-----------+------------+----------+---------------------+-------------+--------------------+-----------+---------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " PRODUCTS SAMPLE:\n",
      "+----------+---------------------------------+-----------------------+-----------+---------------+---------------+---------------+-------------+-------------------------+-----------+-----------------------+---------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+---------------------------------------------+------------------------------------------------------------+----------------------------------------------------------------------+------+\n",
      "|Product_ID|Product_Name                     |Product_Category       |Age_Range  |Opening_Balance|Minimum_Balance|Maximum_Balance|Currency     |Interest_Rate            |Monthly_Fee|Account_Maintenance_Fee|Key_Features                                                                                                               |Digital_Channels                                                |Card_Type                                    |Target_Audience                                             |Special_Benefits                                                      |Status|\n",
      "+----------+---------------------------------+-----------------------+-----------+---------------+---------------+---------------+-------------+-------------------------+-----------+-----------------------+---------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+---------------------------------------------+------------------------------------------------------------+----------------------------------------------------------------------+------+\n",
      "|PROD001   |Zenith Childrens Account (ZECA)  |Savings Account        |0-15 years |0              |0              |No limit       |Naira, Dollar|Competitive              |0          |0                      |Zero opening balance, Scholarship opportunities, Education loan, Customized prepaid card, Annual Children Parade invitation|Zenith Mobile App, *966# EazyBanking, ZIVA                      |Customized Prepaid Card (upon parent request)|Children aged 0-15 years                                    |Teaches children to save, Parents can save for child future           |Active|\n",
      "|PROD002   |Aspire Account                   |Student Savings Account|16-25 years|0              |0              |â‚¦25,000,000    |Naira        |Competitive              |0          |0                      |Zero opening balance, Zero minimum balance, Customized debit card, Discounted card fee â‚¦500                                |Zenith Mobile App, *966# EazyBanking, ZIVA                      |Customized Debit Card                        |Nigerian undergraduate students aged 16-25                  |Enhances student lifestyle, Supports aspirations and dreams           |Active|\n",
      "|PROD003   |Aspire Lite                      |Student Savings Account|16-25 years|0              |0              |â‚¦300,000       |Naira        |Competitive              |0          |0                      |Less documentation, â‚¦50,000 max single deposit, â‚¦20,000 max daily transfer, Aspire Verve debit card                        |Zenith Mobile App, *966# EazyBanking, ZIVA                      |Aspire Debit Card (Verve)                    |Students with limited documentation                         |Easier account opening, Transaction limits for safety                 |Active|\n",
      "|PROD004   |Ethical Savings Account          |Savings Account        |All ages   |0              |0              |No limit       |Naira        |0% (Non-interest bearing)|0          |0                      |Virtual account linked to parent account, No interest, 90-day withdrawal restriction, No minimum deposit                   |Free Email/SMS alerts                                           |N/A                                          |Customers wanting zero-interest savings for specific reasons|Ethical banking option, Helps save for specific goals without interest|Active|\n",
      "|PROD005   |Zenith Individual Current Account|Current Account        |18+ years  |0              |0              |No limit       |Naira        |0%                       |Standard   |Standard               |Zero opening balance, Dividend/draft lodgment, Email/SMS alerts (AlertZ), Free digital banking access                      |Zenith Internet Banking, Mobile Banking, *966# EazyBanking, ZIVA|Zenith Debit and Credit Cards                |Individual customers needing flexible banking               |Flexibility to bank anywhere in the world                             |Active|\n",
      "+----------+---------------------------------+-----------------------+-----------+---------------+---------------+---------------+-------------+-------------------------+-----------+-----------------------+---------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+---------------------------------------------+------------------------------------------------------------+----------------------------------------------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " CUSTOMERS SAMPLE:\n",
      "+-----------+--------------------------+-----------+---------+------+-------------+---+------------+---------------------------------+--------------------------------+----------+-----------+----------+-----------------+-----------------------+--------------+---------------+--------------------------+--------------------+-----------+--------+\n",
      "|Customer_ID|Full_Name                 |First_Name |Last_Name|Gender|Date_of_Birth|Age|Phone_Number|Email                            |Address                         |City      |State      |Occupation|Employment_Status|Income_Bracket         |Marital_Status|Education_Level|Account_Type              |Account_Opening_Date|BVN        |Status  |\n",
      "+-----------+--------------------------+-----------+---------+------+-------------+---+------------+---------------------------------+--------------------------------+----------+-----------+----------+-----------------+-----------------------+--------------+---------------+--------------------------+--------------------+-----------+--------+\n",
      "|ZB000001   |Engr. Chukwuemeka Abubakar|Chukwuemeka|Abubakar |Male  |1993-09-08   |32 |08023756669 |chukwuemeka.abubakar693@gmail.com|9 Allen Avenue, Old Town        |Old Town  |Kwara      |Teacher   |Self-Employed    |â‚¦100,000 - â‚¦250,000    |Married       |PhD            |Individual Current Account|2022-09-18          |68175080694|Inactive|\n",
      "|ZB000002   |Miss Chioma Brown         |Chioma     |Brown    |Female|1980-05-31   |45 |08047295260 |chioma.brown160@yahoo.com        |27 Awolowo Road, New Layout     |New Layout|Sokoto     |Consultant|Employed         |â‚¦1,000,000 - â‚¦2,500,000|Single        |M.Sc           |Individual Current Account|2022-06-23          |84987658854|Active  |\n",
      "|ZB000003   |Dr. Ruth Uzor             |Ruth       |Uzor     |Female|1994-11-23   |30 |08019335534 |ruth.uzor47@yahoo.com            |21 Ahmadu Bello Way, New Layout |New Layout|Sokoto     |Engineer  |Retired          |â‚¦1,000,000 - â‚¦2,500,000|Married       |M.Sc           |Individual Current Account|2022-04-19          |60827117278|Active  |\n",
      "|ZB000004   |Engr. David Brown         |David      |Brown    |Male  |1963-12-30   |61 |08019583482 |david.brown624@yahoo.com         |42 Circular Road, GRA           |GRA       |Cross River|Consultant|Self-Employed    |> â‚¦2,500,000           |Single        |M.Sc           |Timeless Account Current  |2022-01-08          |40305022733|Active  |\n",
      "|ZB000005   |Miss Ngozi Uzor           |Ngozi      |Uzor     |Female|1951-06-21   |74 |08038538251 |ngozi.uzor672@hotmail.com        |37 Independence Avenue, Old Town|Old Town  |Akwa Ibom  |Consultant|Self-Employed    |> â‚¦2,500,000           |Divorced      |M.Sc           |Timeless Account Savings  |2021-09-03          |68345352569|Active  |\n",
      "+-----------+--------------------------+-----------+---------+------+-------------+---+------------+---------------------------------+--------------------------------+----------+-----------+----------+-----------------+-----------------------+--------------+---------------+--------------------------+--------------------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " CONVERSATIONS SAMPLE:\n",
      "+----------+---------------------------------+-----------------------+-----------+---------------+---------------+---------------+-------------+-------------------------+-----------+-----------------------+---------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+---------------------------------------------+------------------------------------------------------------+----------------------------------------------------------------------+------+\n",
      "|Product_ID|Product_Name                     |Product_Category       |Age_Range  |Opening_Balance|Minimum_Balance|Maximum_Balance|Currency     |Interest_Rate            |Monthly_Fee|Account_Maintenance_Fee|Key_Features                                                                                                               |Digital_Channels                                                |Card_Type                                    |Target_Audience                                             |Special_Benefits                                                      |Status|\n",
      "+----------+---------------------------------+-----------------------+-----------+---------------+---------------+---------------+-------------+-------------------------+-----------+-----------------------+---------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+---------------------------------------------+------------------------------------------------------------+----------------------------------------------------------------------+------+\n",
      "|PROD001   |Zenith Childrens Account (ZECA)  |Savings Account        |0-15 years |0              |0              |No limit       |Naira, Dollar|Competitive              |0          |0                      |Zero opening balance, Scholarship opportunities, Education loan, Customized prepaid card, Annual Children Parade invitation|Zenith Mobile App, *966# EazyBanking, ZIVA                      |Customized Prepaid Card (upon parent request)|Children aged 0-15 years                                    |Teaches children to save, Parents can save for child future           |Active|\n",
      "|PROD002   |Aspire Account                   |Student Savings Account|16-25 years|0              |0              |â‚¦25,000,000    |Naira        |Competitive              |0          |0                      |Zero opening balance, Zero minimum balance, Customized debit card, Discounted card fee â‚¦500                                |Zenith Mobile App, *966# EazyBanking, ZIVA                      |Customized Debit Card                        |Nigerian undergraduate students aged 16-25                  |Enhances student lifestyle, Supports aspirations and dreams           |Active|\n",
      "|PROD003   |Aspire Lite                      |Student Savings Account|16-25 years|0              |0              |â‚¦300,000       |Naira        |Competitive              |0          |0                      |Less documentation, â‚¦50,000 max single deposit, â‚¦20,000 max daily transfer, Aspire Verve debit card                        |Zenith Mobile App, *966# EazyBanking, ZIVA                      |Aspire Debit Card (Verve)                    |Students with limited documentation                         |Easier account opening, Transaction limits for safety                 |Active|\n",
      "|PROD004   |Ethical Savings Account          |Savings Account        |All ages   |0              |0              |No limit       |Naira        |0% (Non-interest bearing)|0          |0                      |Virtual account linked to parent account, No interest, 90-day withdrawal restriction, No minimum deposit                   |Free Email/SMS alerts                                           |N/A                                          |Customers wanting zero-interest savings for specific reasons|Ethical banking option, Helps save for specific goals without interest|Active|\n",
      "|PROD005   |Zenith Individual Current Account|Current Account        |18+ years  |0              |0              |No limit       |Naira        |0%                       |Standard   |Standard               |Zero opening balance, Dividend/draft lodgment, Email/SMS alerts (AlertZ), Free digital banking access                      |Zenith Internet Banking, Mobile Banking, *966# EazyBanking, ZIVA|Zenith Debit and Credit Cards                |Individual customers needing flexible banking               |Flexibility to bank anywhere in the world                             |Active|\n",
      "+----------+---------------------------------+-----------------------+-----------+---------------+---------------+---------------+-------------+-------------------------+-----------+-----------------------+---------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+---------------------------------------------+------------------------------------------------------------+----------------------------------------------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " CUSTOMERS SAMPLE:\n",
      "+-----------+--------------------------+-----------+---------+------+-------------+---+------------+---------------------------------+--------------------------------+----------+-----------+----------+-----------------+-----------------------+--------------+---------------+--------------------------+--------------------+-----------+--------+\n",
      "|Customer_ID|Full_Name                 |First_Name |Last_Name|Gender|Date_of_Birth|Age|Phone_Number|Email                            |Address                         |City      |State      |Occupation|Employment_Status|Income_Bracket         |Marital_Status|Education_Level|Account_Type              |Account_Opening_Date|BVN        |Status  |\n",
      "+-----------+--------------------------+-----------+---------+------+-------------+---+------------+---------------------------------+--------------------------------+----------+-----------+----------+-----------------+-----------------------+--------------+---------------+--------------------------+--------------------+-----------+--------+\n",
      "|ZB000001   |Engr. Chukwuemeka Abubakar|Chukwuemeka|Abubakar |Male  |1993-09-08   |32 |08023756669 |chukwuemeka.abubakar693@gmail.com|9 Allen Avenue, Old Town        |Old Town  |Kwara      |Teacher   |Self-Employed    |â‚¦100,000 - â‚¦250,000    |Married       |PhD            |Individual Current Account|2022-09-18          |68175080694|Inactive|\n",
      "|ZB000002   |Miss Chioma Brown         |Chioma     |Brown    |Female|1980-05-31   |45 |08047295260 |chioma.brown160@yahoo.com        |27 Awolowo Road, New Layout     |New Layout|Sokoto     |Consultant|Employed         |â‚¦1,000,000 - â‚¦2,500,000|Single        |M.Sc           |Individual Current Account|2022-06-23          |84987658854|Active  |\n",
      "|ZB000003   |Dr. Ruth Uzor             |Ruth       |Uzor     |Female|1994-11-23   |30 |08019335534 |ruth.uzor47@yahoo.com            |21 Ahmadu Bello Way, New Layout |New Layout|Sokoto     |Engineer  |Retired          |â‚¦1,000,000 - â‚¦2,500,000|Married       |M.Sc           |Individual Current Account|2022-04-19          |60827117278|Active  |\n",
      "|ZB000004   |Engr. David Brown         |David      |Brown    |Male  |1963-12-30   |61 |08019583482 |david.brown624@yahoo.com         |42 Circular Road, GRA           |GRA       |Cross River|Consultant|Self-Employed    |> â‚¦2,500,000           |Single        |M.Sc           |Timeless Account Current  |2022-01-08          |40305022733|Active  |\n",
      "|ZB000005   |Miss Ngozi Uzor           |Ngozi      |Uzor     |Female|1951-06-21   |74 |08038538251 |ngozi.uzor672@hotmail.com        |37 Independence Avenue, Old Town|Old Town  |Akwa Ibom  |Consultant|Self-Employed    |> â‚¦2,500,000           |Divorced      |M.Sc           |Timeless Account Savings  |2021-09-03          |68345352569|Active  |\n",
      "+-----------+--------------------------+-----------+---------+------+-------------+---+------------+---------------------------------+--------------------------------+----------+-----------+----------+-----------------+-----------------------+--------------+---------------+--------------------------+--------------------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " CONVERSATIONS SAMPLE:\n",
      "+-----------+---------------------------------------+------------------+\n",
      "|Customer_ID|Product_Name                           |interaction_score |\n",
      "+-----------+---------------------------------------+------------------+\n",
      "|ZB019348   |Ethical Savings Account                |1.8000000000000003|\n",
      "|ZB019479   |Timeless Savings Account               |1.5000000000000002|\n",
      "|ZB033831   |Zenith Platinum Premium Current Account|2.7               |\n",
      "|ZB034908   |Zenith Salary Savings Account          |1.5000000000000002|\n",
      "|ZB040460   |Salary Advance                         |1.5000000000000002|\n",
      "+-----------+---------------------------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " TRANSACTION STATISTICS:\n",
      "+-----------+---------------------------------------+------------------+\n",
      "|Customer_ID|Product_Name                           |interaction_score |\n",
      "+-----------+---------------------------------------+------------------+\n",
      "|ZB019348   |Ethical Savings Account                |1.8000000000000003|\n",
      "|ZB019479   |Timeless Savings Account               |1.5000000000000002|\n",
      "|ZB033831   |Zenith Platinum Premium Current Account|2.7               |\n",
      "|ZB034908   |Zenith Salary Savings Account          |1.5000000000000002|\n",
      "|ZB040460   |Salary Advance                         |1.5000000000000002|\n",
      "+-----------+---------------------------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " TRANSACTION STATISTICS:\n",
      "+-------+-----------+------------------+----------+----------------+-------------+-------------------------+-----------+---------+------------------------+\n",
      "|summary|Customer_ID|Trans_Amount      |Date      |Destination     |Deb_or_credit|Narration                |Tran_Id    |Category |Account_Type            |\n",
      "+-------+-----------+------------------+----------+----------------+-------------+-------------------------+-----------+---------+------------------------+\n",
      "|count  |1200000    |1200000           |1200000   |1200000         |1200000      |1200000                  |1200000    |1200000  |1200000                 |\n",
      "|mean   |null       |277695.12331866444|null      |null            |null         |null                     |null       |null     |null                    |\n",
      "|stddev |null       |729101.2532123554 |null      |null            |null         |null                     |null       |null     |null                    |\n",
      "|min    |ZB000001   |1000.04           |2023-01-01|9mobile Recharge|C            |DSTV subscription renewal|TR000000001|Dining   |Aspire Account          |\n",
      "|max    |ZB100000   |99999.43          |2024-12-31|Zenith Transfer |D            |weekly shopping          |TR001200000|Utilities|Timeless Account Savings|\n",
      "+-------+-----------+------------------+----------+----------------+-------------+-------------------------+-----------+---------+------------------------+\n",
      "\n",
      "\n",
      " Missing Values Per Column:\n",
      "+-------+-----------+------------------+----------+----------------+-------------+-------------------------+-----------+---------+------------------------+\n",
      "|summary|Customer_ID|Trans_Amount      |Date      |Destination     |Deb_or_credit|Narration                |Tran_Id    |Category |Account_Type            |\n",
      "+-------+-----------+------------------+----------+----------------+-------------+-------------------------+-----------+---------+------------------------+\n",
      "|count  |1200000    |1200000           |1200000   |1200000         |1200000      |1200000                  |1200000    |1200000  |1200000                 |\n",
      "|mean   |null       |277695.12331866444|null      |null            |null         |null                     |null       |null     |null                    |\n",
      "|stddev |null       |729101.2532123554 |null      |null            |null         |null                     |null       |null     |null                    |\n",
      "|min    |ZB000001   |1000.04           |2023-01-01|9mobile Recharge|C            |DSTV subscription renewal|TR000000001|Dining   |Aspire Account          |\n",
      "|max    |ZB100000   |99999.43          |2024-12-31|Zenith Transfer |D            |weekly shopping          |TR001200000|Utilities|Timeless Account Savings|\n",
      "+-------+-----------+------------------+----------+----------------+-------------+-------------------------+-----------+---------+------------------------+\n",
      "\n",
      "\n",
      " Missing Values Per Column:\n",
      "+-----------+------------+----+-----------+-------------+---------+-------+--------+------------+\n",
      "|Customer_ID|Trans_Amount|Date|Destination|Deb_or_credit|Narration|Tran_Id|Category|Account_Type|\n",
      "+-----------+------------+----+-----------+-------------+---------+-------+--------+------------+\n",
      "|0          |0           |0   |0          |0            |0        |0      |0       |0           |\n",
      "+-----------+------------+----+-----------+-------------+---------+-------+--------+------------+\n",
      "\n",
      "\n",
      " DATA OVERVIEW:\n",
      "+-----------+------------+----+-----------+-------------+---------+-------+--------+------------+\n",
      "|Customer_ID|Trans_Amount|Date|Destination|Deb_or_credit|Narration|Tran_Id|Category|Account_Type|\n",
      "+-----------+------------+----+-----------+-------------+---------+-------+--------+------------+\n",
      "|0          |0           |0   |0          |0            |0        |0      |0       |0           |\n",
      "+-----------+------------+----+-----------+-------------+---------+-------+--------+------------+\n",
      "\n",
      "\n",
      " DATA OVERVIEW:\n",
      "Total Rows: 1,200,000\n",
      "Total Rows: 1,200,000\n",
      "Unique Customer_ID: 99,998\n",
      "Unique Customer_ID: 99,998\n",
      "Unique Trans_Amount: 1,131,985\n",
      "Unique Trans_Amount: 1,131,985\n",
      "Unique Date: 731\n",
      "Unique Date: 731\n",
      "Unique Destination: 79\n",
      "Unique Destination: 79\n",
      "Unique Deb_or_credit: 2\n",
      "Unique Deb_or_credit: 2\n",
      "Unique Narration: 83\n",
      "Unique Narration: 83\n",
      "Unique Tran_Id: 1,200,000\n",
      "Unique Tran_Id: 1,200,000\n",
      "Unique Category: 11\n",
      "Unique Category: 11\n",
      "Unique Account_Type: 10\n",
      "Unique Account_Type: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n TRANSACTIONS SAMPLE:\")\n",
    "df_transactions.show(5, truncate=False)\n",
    "\n",
    "print(\"\\n PRODUCTS SAMPLE:\")\n",
    "df_products.show(5, truncate=False)\n",
    "\n",
    "print(\"\\n CUSTOMERS SAMPLE:\")\n",
    "df_customers.show(5, truncate=False)\n",
    "\n",
    "print(\"\\n CONVERSATIONS SAMPLE:\")\n",
    "df_conversations.show(5, truncate=False)\n",
    "\n",
    "print(\"\\n TRANSACTION STATISTICS:\")\n",
    "df_transactions.describe().show(truncate=False)\n",
    "\n",
    "print(\"\\n Missing Values Per Column:\")\n",
    "missing_df = df_transactions.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c)\n",
    "    for c in df_transactions.columns\n",
    "])\n",
    "missing_df.show(truncate=False)\n",
    "\n",
    "print(\"\\n DATA OVERVIEW:\")\n",
    "print(f\"Total Rows: {df_transactions.count():,}\")\n",
    "for col in df_transactions.columns:\n",
    "    unique_count = df_transactions.select(col).distinct().count()\n",
    "    print(f\"Unique {col}: {unique_count:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9933a",
   "metadata": {},
   "source": [
    "## Cell 6: Feature Engineering - Create Interaction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c1391e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Function defined successfully\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window\n",
    "import json\n",
    "from decimal import Decimal\n",
    "\n",
    "def create_customer_product_interactions(df_custs, df_products, df_trans,\n",
    "                                          openai_api_key=None,\n",
    "                                          model_name=\"gpt-4o-mini\",\n",
    "                                          customer_sample_size=None,\n",
    "                                          batch_size=30,\n",
    "                                          temperature=0.3,\n",
    "                                          top_n_products=10,\n",
    "                                          rate_limit_delay=0.5,\n",
    "                                          additional_rules=None,\n",
    "                                          use_transaction_data=True,\n",
    "                                          transaction_weight=0.7):\n",
    "    \"\"\"\n",
    "    HYBRID: Combines OpenAI intelligent matching with real transaction data\n",
    "    Enhanced with transaction description analysis\n",
    "    All parameters configurable, no hard-coded values\n",
    "    Uses Spark for distributed processing\n",
    "   \n",
    "    Args:\n",
    "        df_custs: Customer DataFrame with demographics and Account_Type\n",
    "        df_products: Product catalog DataFrame\n",
    "        df_trans: Transaction DataFrame (with Description field)\n",
    "        openai_api_key: OpenAI API key (required)\n",
    "        model_name: OpenAI model to use\n",
    "        customer_sample_size: Number of customers to process (None = all)\n",
    "        batch_size: Number of customers per API call\n",
    "        temperature: LLM temperature setting\n",
    "        top_n_products: Number of products to recommend per customer\n",
    "        rate_limit_delay: Delay between API calls in seconds\n",
    "        additional_rules: Optional list of custom business rules\n",
    "        use_transaction_data: Whether to include transaction data\n",
    "        transaction_weight: Weight for transaction scores (0-1)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"ðŸ”¨ Creating interaction matrix (Hybrid: OpenAI + Transaction Descriptions)...\\n\")\n",
    "   \n",
    "    # Validate inputs\n",
    "    if openai_api_key is None:\n",
    "        raise ValueError(\"openai_api_key parameter is required\")\n",
    "   \n",
    "    # Initialize OpenAI client\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "   \n",
    "    # Get all product names\n",
    "    all_product_names = [row.Product_Name for row in df_products.select('Product_Name').collect()]\n",
    "    print(f\"   Products in catalog: {len(all_product_names)}\")\n",
    "   \n",
    "    # =========================================================================\n",
    "    # 1. IDENTIFY CURRENT PRODUCTS FROM ACCOUNT_TYPE (SPARK)\n",
    "    # =========================================================================\n",
    "    print(\"\\n   â†’ Identifying current products from Account_Type...\")\n",
    "   \n",
    "    df_custs_with_keywords = df_custs.withColumn(\n",
    "        'account_keywords',\n",
    "        F.regexp_extract(F.lower(F.col('Account_Type')),\n",
    "                        r'(current|savings|sme|student|premium|platinum|children|aspire)', 1)\n",
    "    )\n",
    "   \n",
    "    df_products_keywords = df_products.withColumn(\n",
    "        'product_keywords',\n",
    "        F.regexp_extract(F.lower(F.col('Product_Name')),\n",
    "                        r'(current|savings|sme|student|premium|platinum|children|aspire)', 1)\n",
    "    )\n",
    "   \n",
    "    keyword_map = df_products_keywords.filter(F.col('product_keywords') != '') \\\n",
    "        .select('product_keywords', 'Product_Name') \\\n",
    "        .distinct()\n",
    "   \n",
    "    df_custs_with_current = df_custs_with_keywords.join(\n",
    "        keyword_map,\n",
    "        df_custs_with_keywords.account_keywords == keyword_map.product_keywords,\n",
    "        'left'\n",
    "    ).withColumnRenamed('Product_Name', 'current_product')\n",
    "   \n",
    "    customer_current_products_df = df_custs_with_current.filter(\n",
    "        F.col('current_product').isNotNull()\n",
    "    ).groupBy('Customer_ID').agg(\n",
    "        F.collect_set('current_product').alias('current_products')\n",
    "    )\n",
    "   \n",
    "    current_products_count = customer_current_products_df.count()\n",
    "    print(f\"      Found current products for {current_products_count:,} customers\")\n",
    "   \n",
    "    customer_current_products = {\n",
    "        row.Customer_ID: set(row.current_products)\n",
    "        for row in customer_current_products_df.collect()\n",
    "    }\n",
    "   \n",
    "    # =========================================================================\n",
    "    # 2. PREPARE CUSTOMER PROFILES (SPARK)\n",
    "    # =========================================================================\n",
    "    print(\"\\n   â†’ Preparing customer profiles...\")\n",
    "   \n",
    "    customer_profiles = df_custs.select([c for c in df_custs.columns])\n",
    "    profiles_count = customer_profiles.count()\n",
    "    print(f\"      Total customers: {profiles_count:,}\")\n",
    "   \n",
    "    # =========================================================================\n",
    "    # 3. SAMPLE CUSTOMERS IF SPECIFIED\n",
    "    # =========================================================================\n",
    "    if customer_sample_size is not None and profiles_count > customer_sample_size:\n",
    "        print(f\"      Sampling {customer_sample_size:,} customers from {profiles_count:,} total\")\n",
    "        customer_profiles_sample = customer_profiles.sample(\n",
    "            fraction=customer_sample_size/profiles_count,\n",
    "            seed=42\n",
    "        ).limit(customer_sample_size)\n",
    "    else:\n",
    "        print(f\"      Processing all {profiles_count:,} customers\")\n",
    "        customer_profiles_sample = customer_profiles\n",
    "   \n",
    "    # =========================================================================\n",
    "    # 4. PREPARE PRODUCT CATALOG WITH RULES (SPARK)\n",
    "    # =========================================================================\n",
    "    print(\"\\n   â†’ Preparing product catalog and deriving rules from data...\")\n",
    "   \n",
    "    product_cols = [c for c in df_products.columns]\n",
    "    product_data = df_products.select(product_cols).collect()\n",
    "   \n",
    "    def safe_convert(value):\n",
    "        if value is None:\n",
    "            return None\n",
    "        if isinstance(value, Decimal):\n",
    "            return float(value)\n",
    "        if isinstance(value, (int, float, str, bool)):\n",
    "            return value\n",
    "        return str(value)\n",
    "   \n",
    "    product_catalog = []\n",
    "    for row in product_data:\n",
    "        product_info = {'name': row.Product_Name}\n",
    "        for col in product_cols:\n",
    "            if col != 'Product_Name' and hasattr(row, col):\n",
    "                value = getattr(row, col)\n",
    "                converted_value = safe_convert(value)\n",
    "                if converted_value is not None:\n",
    "                    product_info[col.lower()] = converted_value\n",
    "        product_catalog.append(product_info)\n",
    "   \n",
    "    product_list_parts = []\n",
    "    for i, prod in enumerate(product_catalog):\n",
    "        parts = [f\"{i+1}. {prod['name']}\"]\n",
    "        if 'product_category' in prod:\n",
    "            parts.append(f\"Category: {prod['product_category']}\")\n",
    "        if 'target_audience' in prod:\n",
    "            parts.append(f\"Target: {prod['target_audience']}\")\n",
    "        if 'age_range' in prod:\n",
    "            parts.append(f\"Age Range: {prod['age_range']}\")\n",
    "        if 'minimum_balance' in prod:\n",
    "            try:\n",
    "                min_bal = float(prod['minimum_balance'])\n",
    "                parts.append(f\"Min Balance: â‚¦{min_bal:,.0f}\")\n",
    "            except (ValueError, TypeError):\n",
    "                parts.append(f\"Min Balance: {prod['minimum_balance']}\")\n",
    "        if 'interest_rate' in prod:\n",
    "            parts.append(f\"Interest Rate: {prod['interest_rate']}\")\n",
    "        for key, value in prod.items():\n",
    "            if key not in ['name', 'product_category', 'target_audience', 'age_range', 'minimum_balance', 'interest_rate']:\n",
    "                parts.append(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "        product_list_parts.append(\" - \".join(parts))\n",
    "   \n",
    "    product_list = \"\\n\".join(product_list_parts)\n",
    "   \n",
    "    # =========================================================================\n",
    "    # 5. BUILD DYNAMIC RULES FROM PRODUCT CATALOG\n",
    "    # =========================================================================\n",
    "    print(\"   â†’ Deriving business rules from product catalog...\")\n",
    "   \n",
    "    derived_rules = []\n",
    "    for prod in product_catalog:\n",
    "        prod_name = prod['name']\n",
    "        if 'age_range' in prod and prod['age_range']:\n",
    "            age_range = str(prod['age_range'])\n",
    "            derived_rules.append(f\"- {prod_name}: Only for customers within age range {age_range}\")\n",
    "        if 'target_audience' in prod and prod['target_audience']:\n",
    "            target = prod['target_audience']\n",
    "            derived_rules.append(f\"- {prod_name}: Designed for {target}\")\n",
    "        if 'minimum_balance' in prod and prod['minimum_balance']:\n",
    "            try:\n",
    "                min_bal = float(prod['minimum_balance'])\n",
    "                if min_bal > 0:\n",
    "                    derived_rules.append(f\"- {prod_name}: Requires minimum balance of â‚¦{min_bal:,.0f}\")\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "   \n",
    "    if additional_rules:\n",
    "        derived_rules.extend([f\"- {rule}\" for rule in additional_rules])\n",
    "   \n",
    "    general_rules = [\n",
    "        \"- Match products to customer demographics (age, income, occupation)\",\n",
    "        \"- Do NOT recommend products similar to customer's current account\",\n",
    "        \"- Consider customer's financial capacity when recommending products\",\n",
    "        \"- Respect all age ranges and target audience specifications STRICTLY\"\n",
    "    ]\n",
    "   \n",
    "    all_rules = general_rules + derived_rules\n",
    "    rules_text = \"\\n\".join(all_rules) if all_rules else \"- Match products appropriately to customer profiles\"\n",
    "   \n",
    "    print(f\"      Generated {len(derived_rules)} product-specific rules from catalog\")\n",
    "   \n",
    "    # =========================================================================\n",
    "    # 6. USE OPENAI TO SCORE CUSTOMER-PRODUCT FIT\n",
    "    # =========================================================================\n",
    "    print(\"\\n   â†’ Using OpenAI to score product fit (intelligent matching)...\")\n",
    "    print(\"      This may take time depending on sample size...\")\n",
    "   \n",
    "    customer_profiles_list = customer_profiles_sample.collect()\n",
    "    total_batches = (len(customer_profiles_list) + batch_size - 1) // batch_size\n",
    "    all_interactions = []\n",
    "   \n",
    "    for batch_idx in range(0, len(customer_profiles_list), batch_size):\n",
    "        batch = customer_profiles_list[batch_idx:batch_idx + batch_size]\n",
    "        print(f\"      Processing batch {batch_idx//batch_size + 1}/{total_batches}...\", end='')\n",
    "       \n",
    "        customer_summaries = []\n",
    "        for cust in batch:\n",
    "            summary_parts = [f\"Customer {cust.Customer_ID}:\"]\n",
    "            for col in df_custs.columns:\n",
    "                if col != 'Customer_ID' and hasattr(cust, col):\n",
    "                    value = getattr(cust, col)\n",
    "                    converted_value = safe_convert(value)\n",
    "                    if converted_value is not None:\n",
    "                        summary_parts.append(f\"- {col.replace('_', ' ').title()}: {converted_value}\")\n",
    "            customer_summaries.append('\\n'.join(summary_parts))\n",
    "       \n",
    "        prompt = f\"\"\"You are a banking product recommendation expert. Score how well each product fits each customer on a scale of 0-10.\n",
    " \n",
    "# CUSTOMERS\n",
    "{chr(10).join(customer_summaries)}\n",
    " \n",
    "# PRODUCTS\n",
    "{product_list}\n",
    " \n",
    "# TASK\n",
    "For each customer, score ONLY the top {top_n_products} most relevant products (0-10 scale).\n",
    " \n",
    "# MATCHING RULES\n",
    "{rules_text}\n",
    " \n",
    "Return ONLY valid JSON with this exact structure:\n",
    "{{\n",
    "  \"matches\": [\n",
    "    {{\"customer_id\": \"C001\", \"product\": \"Exact Product Name\", \"score\": 8}},\n",
    "    {{\"customer_id\": \"C001\", \"product\": \"Another Product\", \"score\": 7}}\n",
    "  ]\n",
    "}}\n",
    " \n",
    "Do NOT include any other text, only the JSON object.\"\"\"\n",
    "       \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a banking product expert. Return only valid JSON.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "           \n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            if response_text.startswith('```'):\n",
    "                response_text = response_text.split('```')[1]\n",
    "                if response_text.startswith('json'):\n",
    "                    response_text = response_text[4:]\n",
    "                response_text = response_text.strip()\n",
    "           \n",
    "            result = json.loads(response_text)\n",
    "            for match in result.get('matches', []):\n",
    "                all_interactions.append({\n",
    "                    'Customer_ID': match['customer_id'],\n",
    "                    'Product_Name': match['product'],\n",
    "                    'interaction_score': float(match['score'])\n",
    "                })\n",
    "           \n",
    "            print(f\" âœ“ ({len(result.get('matches', []))} matches)\")\n",
    "        except Exception as e:\n",
    "            print(f\" âœ— Error: {e}\")\n",
    "            continue\n",
    "       \n",
    "        if batch_idx + batch_size < len(customer_profiles_list):\n",
    "            time.sleep(rate_limit_delay)\n",
    "   \n",
    "    # =========================================================================\n",
    "    # 7. CREATE TRANSACTION-BASED INTERACTIONS (WITH DESCRIPTION ANALYSIS)\n",
    "    # =========================================================================\n",
    "    interaction_matrix = None\n",
    "   \n",
    "    if use_transaction_data and df_trans is not None:\n",
    "        print(\"\\n   â†’ Computing transaction-based interaction scores...\")\n",
    "        print(\"      Analyzing transaction descriptions for product signals...\")\n",
    "       \n",
    "        # Get sampled customer IDs\n",
    "        sampled_customer_ids = [row.Customer_ID for row in customer_profiles_sample.select('Customer_ID').collect()]\n",
    "        df_trans_filtered = df_trans.filter(F.col('Customer_ID').isin(sampled_customer_ids))\n",
    "       \n",
    "        trans_filtered_count = df_trans_filtered.count()\n",
    "        print(f\"      Filtered to {trans_filtered_count:,} transactions for sampled customers\")\n",
    "       \n",
    "        # Extract keywords from Account_Type\n",
    "        df_trans_with_keywords = df_trans_filtered.withColumn(\n",
    "            'account_keywords',\n",
    "            F.regexp_extract(F.lower(F.col('Account_Type')),\n",
    "                            r'(current|savings|sme|student|premium|platinum|children|aspire)', 1)\n",
    "        )\n",
    "       \n",
    "        # Extract keywords from Description (if it exists)\n",
    "        if 'Description' in df_trans_filtered.columns:\n",
    "            print(\"      âœ“ Description field found - using for enhanced matching\")\n",
    "            df_trans_with_keywords = df_trans_with_keywords.withColumn(\n",
    "                'desc_keywords',\n",
    "                F.regexp_extract(F.lower(F.col('Description')),\n",
    "                                r'(current|savings|sme|student|premium|platinum|children|aspire|loan|investment|card|transfer|deposit)', 1)\n",
    "            )\n",
    "           \n",
    "            # Combine keywords from both sources\n",
    "            df_trans_with_keywords = df_trans_with_keywords.withColumn(\n",
    "                'combined_keywords',\n",
    "                F.when(F.col('account_keywords') != '', F.col('account_keywords'))\n",
    "                 .when(F.col('desc_keywords') != '', F.col('desc_keywords'))\n",
    "                 .otherwise('')\n",
    "            )\n",
    "        else:\n",
    "            print(\"      âš  Description field not found - using Account_Type only\")\n",
    "            df_trans_with_keywords = df_trans_with_keywords.withColumn(\n",
    "                'combined_keywords',\n",
    "                F.col('account_keywords')\n",
    "            )\n",
    "       \n",
    "        # Match transactions to products using combined keywords\n",
    "        transaction_product_matches = df_trans_with_keywords.join(\n",
    "            keyword_map.withColumnRenamed('product_keywords', 'combined_keywords'),\n",
    "            'combined_keywords',\n",
    "            'inner'\n",
    "        )\n",
    "       \n",
    "        matches_count = transaction_product_matches.count()\n",
    "        print(f\"      Matched {matches_count:,} transactions to products\")\n",
    "       \n",
    "        # Aggregate transaction metrics (RFM Analysis)\n",
    "        transaction_interactions = transaction_product_matches.groupBy('Customer_ID', 'Product_Name').agg(\n",
    "            F.count('*').alias('transaction_count'),\n",
    "            F.sum('Trans_Amount').alias('total_amount'),\n",
    "            F.max('Date').alias('last_transaction_date'),\n",
    "            F.avg('Trans_Amount').alias('avg_amount')\n",
    "        )\n",
    "       \n",
    "        # Calculate recency\n",
    "        max_date = df_trans_filtered.agg(F.max('Date')).collect()[0][0]\n",
    "       \n",
    "        transaction_interactions = transaction_interactions.withColumn(\n",
    "            'days_since_last',\n",
    "            F.datediff(F.lit(max_date), F.col('last_transaction_date'))\n",
    "        )\n",
    "       \n",
    "        # Create RFM-based interaction score (0-10 scale)\n",
    "        print(\"      Computing RFM (Recency, Frequency, Monetary) scores...\")\n",
    "       \n",
    "        # Frequency score: normalize transaction count (log scale for better distribution)\n",
    "        transaction_interactions = transaction_interactions.withColumn(\n",
    "            'frequency_score',\n",
    "            F.least(F.lit(10.0), (F.log1p(F.col('transaction_count')) / F.log1p(F.lit(100.0))) * 10.0)\n",
    "        )\n",
    "       \n",
    "        # Monetary score: normalize total amount (log scale)\n",
    "        transaction_interactions = transaction_interactions.withColumn(\n",
    "            'monetary_score',\n",
    "            F.least(F.lit(10.0), (F.log1p(F.col('total_amount')) / F.log1p(F.lit(1000000.0))) * 10.0)\n",
    "        )\n",
    "       \n",
    "        # Recency score: decay based on days since last transaction\n",
    "        transaction_interactions = transaction_interactions.withColumn(\n",
    "            'recency_score',\n",
    "            F.when(F.col('days_since_last') <= 30, F.lit(10.0))\n",
    "             .when(F.col('days_since_last') <= 60, F.lit(8.0))\n",
    "             .when(F.col('days_since_last') <= 90, F.lit(6.0))\n",
    "             .when(F.col('days_since_last') <= 180, F.lit(4.0))\n",
    "             .when(F.col('days_since_last') <= 365, F.lit(2.0))\n",
    "             .otherwise(F.lit(0.5))\n",
    "        )\n",
    "       \n",
    "        # Combined RFM score with weights\n",
    "        transaction_interactions = transaction_interactions.withColumn(\n",
    "            'transaction_score',\n",
    "            (F.col('frequency_score') * 0.35) +   # 35% frequency\n",
    "            (F.col('monetary_score') * 0.35) +    # 35% monetary\n",
    "            (F.col('recency_score') * 0.30)       # 30% recency\n",
    "        )\n",
    "       \n",
    "        transaction_interactions = transaction_interactions.select(\n",
    "            'Customer_ID',\n",
    "            'Product_Name',\n",
    "            F.col('transaction_score').alias('trans_score'),\n",
    "            'transaction_count',\n",
    "            'total_amount',\n",
    "            'days_since_last'\n",
    "        )\n",
    "       \n",
    "        trans_count = transaction_interactions.count()\n",
    "        print(f\"      Generated {trans_count:,} transaction-based interactions\")\n",
    "       \n",
    "        # Show sample RFM scores\n",
    "        print(\"\\n      Sample RFM scores:\")\n",
    "        transaction_interactions.select(\n",
    "            'Customer_ID', 'Product_Name', 'trans_score',\n",
    "            'transaction_count', 'total_amount', 'days_since_last'\n",
    "        ).show(5, truncate=False)\n",
    "       \n",
    "        # =========================================================================\n",
    "        # 8. MERGE TRANSACTION AND OPENAI SCORES\n",
    "        # =========================================================================\n",
    "        print(\"\\n   â†’ Merging transaction and OpenAI scores...\")\n",
    "       \n",
    "        if not all_interactions:\n",
    "            print(\"      No OpenAI interactions, using transaction data only\")\n",
    "            interaction_matrix = transaction_interactions.select(\n",
    "                'Customer_ID',\n",
    "                'Product_Name',\n",
    "                F.col('trans_score').alias('interaction_score')\n",
    "            )\n",
    "        else:\n",
    "            openai_interactions = spark.createDataFrame(all_interactions)\n",
    "           \n",
    "            # Full outer join\n",
    "            combined = openai_interactions.join(\n",
    "                transaction_interactions.select('Customer_ID', 'Product_Name', 'trans_score'),\n",
    "                ['Customer_ID', 'Product_Name'],\n",
    "                'full_outer'\n",
    "            )\n",
    "           \n",
    "            # Combine scores with weighting\n",
    "            combined = combined.withColumn(\n",
    "                'openai_score',\n",
    "                F.coalesce(F.col('interaction_score'), F.lit(0.0))\n",
    "            ).withColumn(\n",
    "                'trans_score_filled',\n",
    "                F.coalesce(F.col('trans_score'), F.lit(0.0))\n",
    "            ).withColumn(\n",
    "                'interaction_score',\n",
    "                (F.col('trans_score_filled') * transaction_weight) +\n",
    "                (F.col('openai_score') * (1.0 - transaction_weight))\n",
    "            )\n",
    "           \n",
    "            interaction_matrix = combined.select(\n",
    "                'Customer_ID',\n",
    "                'Product_Name',\n",
    "                'interaction_score'\n",
    "            )\n",
    "           \n",
    "            combined_count = interaction_matrix.count()\n",
    "            print(f\"      Combined into {combined_count:,} total interactions\")\n",
    "            print(f\"      Weighting: {transaction_weight*100:.0f}% transactions + {(1-transaction_weight)*100:.0f}% OpenAI\")\n",
    "   \n",
    "    else:\n",
    "        print(\"\\n   â†’ Using OpenAI scores only (no transaction data)\")\n",
    "        if all_interactions:\n",
    "            interaction_matrix = spark.createDataFrame(all_interactions)\n",
    "        else:\n",
    "            print(\"   âš ï¸ No interactions generated. Creating fallback...\")\n",
    "            fallback_count = min(3, len(all_product_names))\n",
    "            fallback_products = all_product_names[:fallback_count]\n",
    "            fallback_data = []\n",
    "            for cust_row in customer_profiles_sample.select('Customer_ID').collect():\n",
    "                for prod in fallback_products:\n",
    "                    fallback_data.append((cust_row.Customer_ID, prod, 5.0))\n",
    "            interaction_matrix = spark.createDataFrame(\n",
    "                fallback_data,\n",
    "                ['Customer_ID', 'Product_Name', 'interaction_score']\n",
    "            )\n",
    "   \n",
    "    # =========================================================================\n",
    "    # 9. AGGREGATE AND FINALIZE\n",
    "    # =========================================================================\n",
    "    print(\"\\n   â†’ Building final interaction matrix...\")\n",
    "   \n",
    "    interaction_matrix = interaction_matrix.groupBy('Customer_ID', 'Product_Name').agg(\n",
    "        F.max('interaction_score').alias('interaction_score')\n",
    "    )\n",
    "   \n",
    "    # =========================================================================\n",
    "    # 10. FILTER OUT CURRENT PRODUCTS\n",
    "    # =========================================================================\n",
    "    print(\"\\n   â†’ Filtering current products...\")\n",
    "   \n",
    "    current_pairs = []\n",
    "    for cust, prods in customer_current_products.items():\n",
    "        for prod in prods:\n",
    "            current_pairs.append((cust, prod))\n",
    "   \n",
    "    if current_pairs:\n",
    "        current_pairs_df = spark.createDataFrame(\n",
    "            current_pairs,\n",
    "            ['Customer_ID', 'Product_Name']\n",
    "        )\n",
    "        interaction_matrix = interaction_matrix.join(\n",
    "            current_pairs_df,\n",
    "            ['Customer_ID', 'Product_Name'],\n",
    "            'left_anti'\n",
    "        )\n",
    "   \n",
    "    elapsed = time.time() - start_time\n",
    "   \n",
    "    # =========================================================================\n",
    "    # FINAL STATS\n",
    "    # =========================================================================\n",
    "    total_interactions = interaction_matrix.count()\n",
    "    unique_customers = interaction_matrix.select('Customer_ID').distinct().count()\n",
    "    unique_products = interaction_matrix.select('Product_Name').distinct().count()\n",
    "   \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"âœ… HYBRID INTERACTION MATRIX CREATED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total interactions: {total_interactions:,}\")\n",
    "    print(f\"Unique customers: {unique_customers:,}\")\n",
    "    print(f\"Unique products: {unique_products:,}\")\n",
    "    print(f\"Products in catalog: {len(product_catalog)}\")\n",
    "    print(f\"\\nðŸ§  {model_name} + Transaction Data:\")\n",
    "    print(f\"   â€¢ {len(derived_rules)} rules derived from product catalog\")\n",
    "    print(f\"   â€¢ {len(additional_rules) if additional_rules else 0} custom business rules\")\n",
    "    print(f\"   â€¢ Customer demographics and attributes\")\n",
    "    if use_transaction_data:\n",
    "        print(f\"   â€¢ Real transaction history with descriptions (weight: {transaction_weight*100:.0f}%)\")\n",
    "        print(f\"   â€¢ RFM analysis: Recency (30%) + Frequency (35%) + Monetary (35%)\")\n",
    "    print(f\"\\nâš ï¸ Current products EXCLUDED from recommendations\")\n",
    "    print(f\"   Customers with current products: {len(customer_current_products):,}\")\n",
    "    print(f\"\\nâš¡ Completed in {elapsed:.1f} seconds\")\n",
    "    print(f\"   Model used: {model_name}\")\n",
    "    print(\"=\"*80)\n",
    "   \n",
    "    return interaction_matrix, df_products, customer_current_products\n",
    "\n",
    "print(\"âœ… Function defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff83453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Starting Hybrid interaction matrix creation...\n",
      "\n",
      "ðŸ”¨ Creating interaction matrix (Hybrid: OpenAI + Transaction Descriptions)...\n",
      "\n",
      "   Products in catalog: 42\n",
      "\n",
      "   â†’ Identifying current products from Account_Type...\n",
      "   Products in catalog: 42\n",
      "\n",
      "   â†’ Identifying current products from Account_Type...\n",
      "      Found current products for 92,202 customers\n",
      "      Found current products for 92,202 customers\n",
      "\n",
      "   â†’ Preparing customer profiles...\n",
      "\n",
      "   â†’ Preparing customer profiles...\n",
      "      Total customers: 100,000\n",
      "      Sampling 1,000 customers from 100,000 total\n",
      "\n",
      "   â†’ Preparing product catalog and deriving rules from data...\n",
      "   â†’ Deriving business rules from product catalog...\n",
      "      Generated 86 product-specific rules from catalog\n",
      "\n",
      "   â†’ Using OpenAI to score product fit (intelligent matching)...\n",
      "      This may take time depending on sample size...\n",
      "      Total customers: 100,000\n",
      "      Sampling 1,000 customers from 100,000 total\n",
      "\n",
      "   â†’ Preparing product catalog and deriving rules from data...\n",
      "   â†’ Deriving business rules from product catalog...\n",
      "      Generated 86 product-specific rules from catalog\n",
      "\n",
      "   â†’ Using OpenAI to score product fit (intelligent matching)...\n",
      "      This may take time depending on sample size...\n",
      "      Processing batch 1/34...      Processing batch 1/34..."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXECUTE: Hybrid Interaction Matrix Generation\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nðŸš€ Starting Hybrid interaction matrix creation...\\n\")\n",
    "\n",
    "custom_rules = [\n",
    "    \"Premium products require demonstrated high transaction volumes\",\n",
    "    \"Savings products are suitable for customers with stable income\"\n",
    "]\n",
    "\n",
    "interaction_df, product_map, customer_current_products = create_customer_product_interactions(\n",
    "    df_customers,\n",
    "    df_products,\n",
    "    df_transactions,                # Transaction data with descriptions\n",
    "    openai_api_key=openai_api_key,\n",
    "    model_name=CONFIG['llm']['model'],\n",
    "    customer_sample_size=1000,\n",
    "    batch_size=30,\n",
    "    temperature=CONFIG['llm']['temperature'],\n",
    "    top_n_products=CONFIG['recommendation']['top_n'],\n",
    "    rate_limit_delay=0.5,\n",
    "    additional_rules=custom_rules,\n",
    "    use_transaction_data=True,      # Enable transaction data\n",
    "    transaction_weight=0.7           # 70% transactions, 30% OpenAI\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“Š Sample Interactions:\")\n",
    "interaction_df.show(10)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Score Distribution:\")\n",
    "interaction_df.describe(['interaction_score']).show()\n",
    "\n",
    "print(\"\\nðŸ“ˆ Top Products by Interaction Count:\")\n",
    "top_products = interaction_df.groupBy('Product_Name').count().orderBy(F.desc('count')).limit(10)\n",
    "top_products.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9de189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
